{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c33416-d9d7-4534-b57e-72cfcb0c50f7",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37fe8fa4-1223-4e21-bb1e-f2beb1bd1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.10\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3.10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e88ae63-c475-456f-9f2d-19ab29f5e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, sum, avg, max, count,\n",
    "    countDistinct\n",
    ")\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer,\n",
    "    OneHotEncoder,\n",
    "    VectorAssembler,\n",
    "    StandardScaler\n",
    ")\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41dc891-45ec-4ce3-8681-52e045ba2a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/27 22:02:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FraudDetection\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb338b72-52a9-4535-9d4e-984332caadc8",
   "metadata": {},
   "source": [
    "### Load data from CSV into a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9cda6c-fcfa-4ade-8b50-8cd0f3cb7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = spark.read.csv(\n",
    "    \"data/transactions.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "loan_apps = spark.read.csv(\n",
    "    \"data/loan_applications.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc249d2-b034-431e-8f80-c3e30bec7b2d",
   "metadata": {},
   "source": [
    "### Check dataframes schemas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71adae24-787d-44c6-95c9-47733cd26ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- transaction_date: timestamp (nullable = true)\n",
      " |-- transaction_type: string (nullable = true)\n",
      " |-- transaction_amount: double (nullable = true)\n",
      " |-- merchant_category: string (nullable = true)\n",
      " |-- merchant_name: string (nullable = true)\n",
      " |-- transaction_location: string (nullable = true)\n",
      " |-- account_balance_after_transaction: double (nullable = true)\n",
      " |-- is_international_transaction: integer (nullable = true)\n",
      " |-- device_used: string (nullable = true)\n",
      " |-- ip_address: string (nullable = true)\n",
      " |-- transaction_status: string (nullable = true)\n",
      " |-- transaction_source_destination: string (nullable = true)\n",
      " |-- transaction_notes: string (nullable = true)\n",
      " |-- fraud_flag: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672292e7-37b3-49a9-874c-84f9bb67d6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- application_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- application_date: date (nullable = true)\n",
      " |-- loan_type: string (nullable = true)\n",
      " |-- loan_amount_requested: double (nullable = true)\n",
      " |-- loan_tenure_months: integer (nullable = true)\n",
      " |-- interest_rate_offered: double (nullable = true)\n",
      " |-- purpose_of_loan: string (nullable = true)\n",
      " |-- employment_status: string (nullable = true)\n",
      " |-- monthly_income: double (nullable = true)\n",
      " |-- cibil_score: integer (nullable = true)\n",
      " |-- existing_emis_monthly: double (nullable = true)\n",
      " |-- debt_to_income_ratio: double (nullable = true)\n",
      " |-- property_ownership_status: string (nullable = true)\n",
      " |-- residential_address: string (nullable = true)\n",
      " |-- applicant_age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- number_of_dependents: integer (nullable = true)\n",
      " |-- loan_status: string (nullable = true)\n",
      " |-- fraud_flag: integer (nullable = true)\n",
      " |-- fraud_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_apps.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905c674-c9df-422c-872a-696e992f25d2",
   "metadata": {},
   "source": [
    "### Drop Unecessary columns from transactions and loan_apps dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd4436c-a109-4e3f-81df-59e86671e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.drop(\n",
    "    \"ip_address\",\n",
    "    \"transaction_notes\",\n",
    "    \"transaction_location\",\n",
    "    \"transaction_source_destination\"\n",
    ")\n",
    "\n",
    "loan_apps = loan_apps.drop(\n",
    "\n",
    "    \"residential_address\",\n",
    "    \"fraud_type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cb49bd5-f639-4d2c-b88b-9fc050762c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_txn_df = loan_apps.select(\n",
    "    \"customer_id\",\n",
    "    \"application_date\"\n",
    ").join(\n",
    "    transactions,\n",
    "    on=\"customer_id\",\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c73b3-b935-4791-a9f6-75e1446fc200",
   "metadata": {},
   "source": [
    "### Filter the transactions (only keep the ones made before the loan application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a70065ef-e544-4b65-84a2-c07805f846fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "txn_df = loan_txn_df.filter(\n",
    "    col(\"transaction_date\") < col(\"application_date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a90ea9-4020-407f-8adc-6a60b9c058a5",
   "metadata": {},
   "source": [
    "### Feature Engineering on transactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3046e50-5ff1-4175-a57d-d67694a977bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "txn_agg = txn_df.groupBy(\"customer_id\").agg(\n",
    "    count(\"*\").alias(\"txn_count\"),\n",
    "    sum(\"transaction_amount\").alias(\"total_txn_amount\"),\n",
    "    avg(\"transaction_amount\").alias(\"avg_txn_amount\"),\n",
    "    max(\"transaction_amount\").alias(\"max_txn_amount\"),\n",
    "\n",
    "    sum(when(col(\"is_international_transaction\") == 1, 1).otherwise(0))\n",
    "        .alias(\"international_txn_count\"),\n",
    "\n",
    "    countDistinct(\"merchant_name\").alias(\"unique_merchants\"),\n",
    "    countDistinct(\"merchant_category\").alias(\"unique_merchant_categories\"),\n",
    "\n",
    "    sum(when(col(\"transaction_status\") == \"Failed\", 1).otherwise(0))\n",
    "        .alias(\"failed_txn_count\"),\n",
    "    \n",
    "    sum(when(col(\"fraud_flag\") == 1, 1).otherwise(0))\n",
    "        .alias(\"fraud_flag_txn_count\"),\n",
    "\n",
    "    avg(\"account_balance_after_transaction\").alias(\"avg_post_balance\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "981e288a-d904-4865-b29d-fc807a3bb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "txn_agg = txn_agg.withColumn(\n",
    "    \"international_txn_ratio\",\n",
    "    when(col(\"txn_count\") > 0, col(\"international_txn_count\") / col(\"txn_count\"))\n",
    "    .otherwise(0)\n",
    ").withColumn(\n",
    "    \"failed_txn_ratio\",\n",
    "    when(col(\"txn_count\") > 0, col(\"failed_txn_count\") / col(\"txn_count\"))\n",
    "    .otherwise(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7c1b05-32cf-4553-911a-1ab6380f1ff2",
   "metadata": {},
   "source": [
    "### Merge the dataframes to get advantage of transactions history of customers for loan fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "476557c8-d382-4302-b395-2478d6aec4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = loan_apps.join(\n",
    "    txn_agg,\n",
    "    on=\"customer_id\",\n",
    "    how=\"inner\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa3c566-f050-4f9e-8c8c-dde6766e9007",
   "metadata": {},
   "source": [
    "### Feature engineering on loan applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83f6dc7d-a7b0-4f2c-976b-97dbf13bcb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.withColumn(\n",
    "    \"loan_to_income_ratio\",\n",
    "    col(\"loan_amount_requested\") / (col(\"monthly_income\") + 1)\n",
    ").withColumn(\n",
    "    \"emi_burden_ratio\",\n",
    "    col(\"existing_emis_monthly\") / (col(\"monthly_income\") + 1)\n",
    ").withColumn(\n",
    "    \"is_high_risk_age\",\n",
    "    when((col(\"applicant_age\") < 21) | (col(\"applicant_age\") > 65), 1).otherwise(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60f76bbd-4835-48c5-ae8c-1ba761e07706",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.withColumn(\n",
    "    \"age_bucket\",\n",
    "    when(col(\"applicant_age\") < 21, \"very_young\")\n",
    "    .when((col(\"applicant_age\") >= 21) & (col(\"applicant_age\") <= 25), \"young\")\n",
    "    .when((col(\"applicant_age\") >= 26) & (col(\"applicant_age\") <= 35), \"early_career\")\n",
    "    .when((col(\"applicant_age\") >= 36) & (col(\"applicant_age\") <= 50), \"mid_career\")\n",
    "    .when((col(\"applicant_age\") >= 51) & (col(\"applicant_age\") <= 65), \"senior\")\n",
    "    .otherwise(\"elderly\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eed0a0cf-452f-4443-8b10-84feda86ea1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- application_id: string (nullable = true)\n",
      " |-- application_date: date (nullable = true)\n",
      " |-- loan_type: string (nullable = true)\n",
      " |-- loan_amount_requested: double (nullable = true)\n",
      " |-- loan_tenure_months: integer (nullable = true)\n",
      " |-- interest_rate_offered: double (nullable = true)\n",
      " |-- purpose_of_loan: string (nullable = true)\n",
      " |-- employment_status: string (nullable = true)\n",
      " |-- monthly_income: double (nullable = true)\n",
      " |-- cibil_score: integer (nullable = true)\n",
      " |-- existing_emis_monthly: double (nullable = true)\n",
      " |-- debt_to_income_ratio: double (nullable = true)\n",
      " |-- property_ownership_status: string (nullable = true)\n",
      " |-- applicant_age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- number_of_dependents: integer (nullable = true)\n",
      " |-- loan_status: string (nullable = true)\n",
      " |-- fraud_flag: integer (nullable = true)\n",
      " |-- txn_count: long (nullable = false)\n",
      " |-- total_txn_amount: double (nullable = true)\n",
      " |-- avg_txn_amount: double (nullable = true)\n",
      " |-- max_txn_amount: double (nullable = true)\n",
      " |-- international_txn_count: long (nullable = true)\n",
      " |-- unique_merchants: long (nullable = false)\n",
      " |-- unique_merchant_categories: long (nullable = false)\n",
      " |-- failed_txn_count: long (nullable = true)\n",
      " |-- fraud_flag_txn_count: long (nullable = true)\n",
      " |-- avg_post_balance: double (nullable = true)\n",
      " |-- international_txn_ratio: double (nullable = true)\n",
      " |-- failed_txn_ratio: double (nullable = true)\n",
      " |-- loan_to_income_ratio: double (nullable = true)\n",
      " |-- emi_burden_ratio: double (nullable = true)\n",
      " |-- is_high_risk_age: integer (nullable = false)\n",
      " |-- age_bucket: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f14c7a-76b0-4d9e-b40f-c6c90eadf84d",
   "metadata": {},
   "source": [
    "### Drop Uncessary columns for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "393ecb32-6793-4833-a148-a233c25bb271",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.drop(\n",
    "\n",
    "    \"customer_id\",\n",
    "    \"application_id\",\n",
    "     \"application_date\",\n",
    "    \"applicant_age\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09a9a4e4-70d5-4d04-aaf9-07c6e91b8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"loan_type\", \n",
    "                    \"purpose_of_loan\",\n",
    "                    \"employment_status\",\n",
    "                    \"property_ownership_status\",\n",
    "                    \"gender\",\n",
    "                    \"loan_status\",\n",
    "                    \"age_bucket\"\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                   ]\n",
    "numeric_cols = [\"loan_amount_requested\", \n",
    "                \"loan_tenure_months\",\n",
    "                \"interest_rate_offered\",\n",
    "                \"monthly_income\",\n",
    "                \"cibil_score\",\n",
    "                \"existing_emis_monthly\",\n",
    "                \"debt_to_income_ratio\",\n",
    "                \"number_of_dependents\",\n",
    "                \"txn_count\",\n",
    "                \"total_txn_amount\",\n",
    "                \"avg_txn_amount\",\n",
    "                \"max_txn_amount\",\n",
    "                \"international_txn_count\",\n",
    "                \"unique_merchants\",\n",
    "                \"unique_merchant_categories\",\n",
    "                \"failed_txn_count\",\n",
    "                \"fraud_flag_txn_count\",\n",
    "                \"avg_post_balance\",\n",
    "                \"international_txn_ratio\",\n",
    "                \"failed_txn_ratio\",\n",
    "                \"loan_to_income_ratio\",\n",
    "                \"emi_burden_ratio\",\n",
    "                \"is_high_risk_age\"\n",
    "                \n",
    "                          \n",
    "                \n",
    "                \n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78c156e4-fecf-42ef-ad54-b67d0c4931fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [\n",
    "    StringIndexer(\n",
    "        inputCol=col,\n",
    "        outputCol=f\"{col}_idx\",\n",
    "        handleInvalid=\"keep\"\n",
    "    )\n",
    "    for col in categorical_cols\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9498d007-81db-4ac0-99e6-81af6973dc21",
   "metadata": {},
   "source": [
    "### Encode categorical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66c9fd91-b452-4240-9ff3-0f7bfaa08853",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[f\"{col}_idx\" for col in categorical_cols] + numeric_cols,\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e2c35-4737-4e36-a0b0-eeed1667384a",
   "metadata": {},
   "source": [
    "### Perform Stratified split since the dataset is unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f10069a7-5d4a-47fb-9df2-4e7c1d95a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = \"fraud_flag\"\n",
    "\n",
    "fractions = {\n",
    "    0.0: 0.8,\n",
    "    1.0: 0.8\n",
    "}\n",
    "\n",
    "train_df = full_df.sampleBy(\n",
    "    col=label_col,\n",
    "    fractions=fractions,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_df = full_df.subtract(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "695aaa3f-d0df-44ec-a7a0-bd07f4172352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|fraud_flag|count|\n",
      "+----------+-----+\n",
      "|         1|  749|\n",
      "|         0|35876|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/27 22:02:41 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 25:>                                                       (0 + 11) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|fraud_flag|count|\n",
      "+----------+-----+\n",
      "|         1|  181|\n",
      "|         0| 8991|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df.groupBy(label_col).count().show()\n",
    "test_df.groupBy(label_col).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69bb2db-8b7b-45ea-ba51-e28cec1875a6",
   "metadata": {},
   "source": [
    "## Train and Evaluate random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ad504ba-fcb2-4ad3-927b-8e07b631c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"fraud_flag\",\n",
    "    numTrees=100,\n",
    "    maxDepth=10,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acaf3517-0271-4103-9cef-e5e7be59c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages=indexers + [assembler, rf]\n",
    ")\n",
    "\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b13fbd28-44fc-4daf-a258-d0b34c07bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09264967-6849-470c-87b2-55ccecb0f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"fraud_flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b870eb40-8902-4e98-a162-036b3e9e3d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9999978492918947\n"
     ]
    }
   ],
   "source": [
    "auc = evaluator.evaluate(predictions)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f40f1c2a-0c98-492a-a63a-49d5675ac7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+\n",
      "|fraud_flag|prediction|count|\n",
      "+----------+----------+-----+\n",
      "|         0|       0.0| 8991|\n",
      "|         1|       1.0|  181|\n",
      "+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = (\n",
    "    predictions\n",
    "    .groupBy(\"fraud_flag\", \"prediction\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcfae363-d1e7-46e6-bc13-43f1362b67b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, when, coalesce, lit\n",
    "\n",
    "stats = (\n",
    "    cm\n",
    "    .groupBy(\"fraud_flag\")\n",
    "    .agg(\n",
    "        coalesce(\n",
    "            _sum(when(col(\"fraud_flag\") == col(\"prediction\"), col(\"count\"))),\n",
    "            lit(0)\n",
    "        ).alias(\"TP\"),\n",
    "        coalesce(\n",
    "            _sum(when(col(\"fraud_flag\") != col(\"prediction\"), col(\"count\"))),\n",
    "            lit(0)\n",
    "        ).alias(\"FN\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be930fd6-12cd-49c1-9591-645078491db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = (\n",
    "    cm\n",
    "    .groupBy(\"prediction\")\n",
    "    .agg(_sum(\"count\").alias(\"predicted_total\"))\n",
    "    .withColumnRenamed(\"prediction\", \"fraud_flag\")\n",
    ")\n",
    "\n",
    "stats = stats.join(fp, \"fraud_flag\")\n",
    "stats = stats.withColumn(\"FP\", col(\"predicted_total\") - col(\"TP\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8f759ba-fa99-47e6-92e6-337a1b251fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/27 22:03:01 WARN DAGScheduler: Broadcasting large task binary with size 1014.9 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+---+\n",
      "|fraud_flag|precision|recall| f1|\n",
      "+----------+---------+------+---+\n",
      "|         1|      1.0|   1.0|1.0|\n",
      "|         0|      1.0|   1.0|1.0|\n",
      "+----------+---------+------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/27 22:03:02 WARN DAGScheduler: Broadcasting large task binary with size 1253.3 KiB\n"
     ]
    }
   ],
   "source": [
    "stats = (\n",
    "    stats\n",
    "    .withColumn(\"precision\", col(\"TP\") / (col(\"TP\") + col(\"FP\")))\n",
    "    .withColumn(\"recall\", col(\"TP\") / (col(\"TP\") + col(\"FN\")))\n",
    "    .withColumn(\"f1\", 2 * col(\"precision\") * col(\"recall\") /\n",
    "                        (col(\"precision\") + col(\"recall\")))\n",
    ")\n",
    "\n",
    "stats.select(\"fraud_flag\", \"precision\", \"recall\", \"f1\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab565dae-baa5-491c-8c84-2421f175d5dd",
   "metadata": {},
   "source": [
    "## Train and Evaluate Logistic Regression Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd09b169-dc58-489f-aee4-7438f074cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"fraud_flag\",\n",
    "    maxIter=100,\n",
    "    regParam=0.0,\n",
    "    elasticNetParam=0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d782c5c-99a4-40ff-b566-09a120d09811",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages=indexers + [assembler, lr]\n",
    ")\n",
    "\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c90b3a2-34a1-4207-85cb-8e43d16570fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55611dc8-fd6d-47d7-893d-3a4ddf9d9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"fraud_flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3529408-ace2-4f1d-ba2e-ce3ac936b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9999975420478796\n"
     ]
    }
   ],
   "source": [
    "auc = evaluator.evaluate(predictions)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02368650-11f1-42e6-84d5-e46cd7e7ea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+\n",
      "|fraud_flag|prediction|count|\n",
      "+----------+----------+-----+\n",
      "|         0|       0.0| 8991|\n",
      "|         1|       1.0|  181|\n",
      "+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = (\n",
    "    predictions\n",
    "    .groupBy(\"fraud_flag\", \"prediction\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d151666-9075-4370-8c3c-6d74c0605f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, when, coalesce, lit\n",
    "\n",
    "stats = (\n",
    "    cm\n",
    "    .groupBy(\"fraud_flag\")\n",
    "    .agg(\n",
    "        coalesce(\n",
    "            _sum(when(col(\"fraud_flag\") == col(\"prediction\"), col(\"count\"))),\n",
    "            lit(0)\n",
    "        ).alias(\"TP\"),\n",
    "        coalesce(\n",
    "            _sum(when(col(\"fraud_flag\") != col(\"prediction\"), col(\"count\"))),\n",
    "            lit(0)\n",
    "        ).alias(\"FN\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64122c3e-3a46-47f0-872d-449191b08f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = (\n",
    "    cm\n",
    "    .groupBy(\"prediction\")\n",
    "    .agg(_sum(\"count\").alias(\"predicted_total\"))\n",
    "    .withColumnRenamed(\"prediction\", \"fraud_flag\")\n",
    ")\n",
    "\n",
    "stats = stats.join(fp, \"fraud_flag\")\n",
    "stats = stats.withColumn(\"FP\", col(\"predicted_total\") - col(\"TP\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15b4fa74-152b-40d4-9415-ccde9d3d0124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 610:=============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+---+\n",
      "|fraud_flag|precision|recall| f1|\n",
      "+----------+---------+------+---+\n",
      "|         1|      1.0|   1.0|1.0|\n",
      "|         0|      1.0|   1.0|1.0|\n",
      "+----------+---------+------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stats = (\n",
    "    stats\n",
    "    .withColumn(\"precision\", col(\"TP\") / (col(\"TP\") + col(\"FP\")))\n",
    "    .withColumn(\"recall\", col(\"TP\") / (col(\"TP\") + col(\"FN\")))\n",
    "    .withColumn(\"f1\", 2 * col(\"precision\") * col(\"recall\") /\n",
    "                        (col(\"precision\") + col(\"recall\")))\n",
    ")\n",
    "\n",
    "stats.select(\"fraud_flag\", \"precision\", \"recall\", \"f1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551b77e8-ef09-4ccb-a360-9757bdb8d583",
   "metadata": {},
   "source": [
    "### Train a Gradient-Boosted Tree classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e0fee7a-a213-45a0-8274-3265cd5cf3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"fraud_flag\",\n",
    "    maxIter=100,\n",
    "    maxDepth=5,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "947c26e7-4e64-4b6c-9b5d-9fb637f5c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages=indexers + [assembler, gbt]\n",
    ")\n",
    "\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "146ada9c-bd1b-40b9-96f5-c71f7c05a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f76e16c-e80c-4bfd-8741-1b226c9596ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"fraud_flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4705a99-c4d5-4a3d-8c25-357baa5255ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "auc = evaluator.evaluate(predictions)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "31b38c91-9124-45d5-8f36-0499aa9b38f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+\n",
      "|fraud_flag|prediction|count|\n",
      "+----------+----------+-----+\n",
      "|         0|       0.0| 8991|\n",
      "|         1|       1.0|  181|\n",
      "+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = (\n",
    "    predictions\n",
    "    .groupBy(\"fraud_flag\", \"prediction\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b1635a5-dc37-4cf7-aa5b-e2528124f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, when, coalesce, lit\n",
    "\n",
    "stats = (\n",
    "    cm\n",
    "    .groupBy(\"fraud_flag\")\n",
    "    .agg(\n",
    "        coalesce(\n",
    "            _sum(when(col(\"fraud_flag\") == col(\"prediction\"), col(\"count\"))),\n",
    "            lit(0)\n",
    "        ).alias(\"TP\"),\n",
    "        coalesce(\n",
    "            _sum(when(col(\"fraud_flag\") != col(\"prediction\"), col(\"count\"))),\n",
    "            lit(0)\n",
    "        ).alias(\"FN\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6cf7adf8-8b0e-4d80-8749-a9ee3132de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = (\n",
    "    cm\n",
    "    .groupBy(\"prediction\")\n",
    "    .agg(_sum(\"count\").alias(\"predicted_total\"))\n",
    "    .withColumnRenamed(\"prediction\", \"fraud_flag\")\n",
    ")\n",
    "\n",
    "stats = stats.join(fp, \"fraud_flag\")\n",
    "stats = stats.withColumn(\"FP\", col(\"predicted_total\") - col(\"TP\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "181b493f-8d7e-40f4-82a2-2a8da003bbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7769:============> (10 + 1) / 11][Stage 7774:======>        (5 + 6) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+---+\n",
      "|fraud_flag|precision|recall| f1|\n",
      "+----------+---------+------+---+\n",
      "|         1|      1.0|   1.0|1.0|\n",
      "|         0|      1.0|   1.0|1.0|\n",
      "+----------+---------+------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stats = (\n",
    "    stats\n",
    "    .withColumn(\"precision\", col(\"TP\") / (col(\"TP\") + col(\"FP\")))\n",
    "    .withColumn(\"recall\", col(\"TP\") / (col(\"TP\") + col(\"FN\")))\n",
    "    .withColumn(\"f1\", 2 * col(\"precision\") * col(\"recall\") /\n",
    "                        (col(\"precision\") + col(\"recall\")))\n",
    ")\n",
    "\n",
    "stats.select(\"fraud_flag\", \"precision\", \"recall\", \"f1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdef88e-19b5-40eb-bcbb-c5e7d087389f",
   "metadata": {},
   "source": [
    "## Optimized version â€” CrossValidator + ParamGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "19092f21-467b-4c06-bb15-2d154b5a26ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [50, 100]) \\\n",
    "    .addGrid(gbt.maxDepth, [3, 5]) \\\n",
    "    .addGrid(gbt.stepSize, [0.05, 0.1]) \\\n",
    "    .build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "56fcde96-dfb8-4ef0-9270-90035230cfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"fraud_flag\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c5d62b0-ce8e-40b5-aaa5-e97b4f16557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "cv_gbt = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5,\n",
    "    parallelism=4  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5134e0a8-3e41-4ce4-b9d2-c22a9ebc4f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/27 22:50:32 WARN BlockManager: Asked to remove block broadcast_10803_piece0, which does not exist\n",
      "26/01/27 22:50:32 WARN BlockManager: Asked to remove block broadcast_10803, which does not exist\n",
      "26/01/27 23:01:57 WARN BlockManager: Asked to remove block broadcast_13385, which does not exist\n",
      "26/01/27 23:20:56 WARN CacheManager: Asked to cache already cached data.        200]]\n",
      "26/01/27 23:20:56 WARN CacheManager: Asked to cache already cached data.\n",
      "26/01/27 23:30:10 WARN BlockManager: Asked to remove block broadcast_19208, which does not exist\n",
      "                                                                                200]]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_gbt_model = cv_gbt.fit(train_df)\n",
    "\n",
    "gbt_cv_preds = cv_gbt_model.transform(test_df)\n",
    "\n",
    "gbt_cv_f1 = evaluator.evaluate(gbt_cv_preds)\n",
    "gbt_cv_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d8919b5-4550-4697-bf46-deb1827190b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best maxIter: 50\n",
      "Best maxDepth: 3\n",
      "Best stepSize: 0.05\n"
     ]
    }
   ],
   "source": [
    "best_model = cv_gbt_model.bestModel\n",
    "best_gbt = best_model.stages[-1]\n",
    "\n",
    "print(\"Best maxIter:\", best_gbt.getMaxIter())\n",
    "print(\"Best maxDepth:\", best_gbt.getMaxDepth())\n",
    "print(\"Best stepSize:\", best_gbt.getStepSize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79fb404-7e0c-48c1-b2a0-a394aca9068e",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55b2338f-793d-4a66-8b05-b4e35f867db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "svm = LinearSVC(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"fraud_flag\",\n",
    "    maxIter=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df491189-3a65-4c1d-8b39-0016b63a2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages=indexers + [assembler, svm]\n",
    ")\n",
    "\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "206130ab-383c-4320-af05-29f61303bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b98c8c81-7f63-4edf-b82e-90c74351ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"fraud_flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b0da931-d077-47af-8997-db96613be1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9999975420478796\n"
     ]
    }
   ],
   "source": [
    "auc = evaluator.evaluate(predictions)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8cab0362-e459-411c-bd03-089e2bdd4d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+\n",
      "|fraud_flag|prediction|count|\n",
      "+----------+----------+-----+\n",
      "|         0|       0.0| 8991|\n",
      "|         1|       1.0|  181|\n",
      "+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = (\n",
    "    predictions\n",
    "    .groupBy(\"fraud_flag\", \"prediction\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35aec5e9-c5fe-4b61-8b85-0689186caacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, when, coalesce, lit\n",
    "\n",
    "stats = (\n",
    "    cm\n",
    "    .groupBy(\"fraud_flag\")\n",
    "    .agg(\n",
    "        coalesce(\n",
    "            _sum(when(col(\"fraud_flag\") == col(\"prediction\"), col(\"count\"))),\n",
    "            lit(0)\n",
    "        ).alias(\"TP\"),\n",
    "        coalesce(\n",
    "            _sum(when(col(\"fraud_flag\") != col(\"prediction\"), col(\"count\"))),\n",
    "            lit(0)\n",
    "        ).alias(\"FN\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c32c9a11-df85-4ce8-b84a-5563a30e4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = (\n",
    "    cm\n",
    "    .groupBy(\"prediction\")\n",
    "    .agg(_sum(\"count\").alias(\"predicted_total\"))\n",
    "    .withColumnRenamed(\"prediction\", \"fraud_flag\")\n",
    ")\n",
    "\n",
    "stats = stats.join(fp, \"fraud_flag\")\n",
    "stats = stats.withColumn(\"FP\", col(\"predicted_total\") - col(\"TP\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a16f1d1-953f-4d0d-9100-47dea783c706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3608:=================================================>    (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+---+\n",
      "|fraud_flag|precision|recall| f1|\n",
      "+----------+---------+------+---+\n",
      "|         0|      1.0|   1.0|1.0|\n",
      "|         1|      1.0|   1.0|1.0|\n",
      "+----------+---------+------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stats = (\n",
    "    stats\n",
    "    .withColumn(\"precision\", col(\"TP\") / (col(\"TP\") + col(\"FP\")))\n",
    "    .withColumn(\"recall\", col(\"TP\") / (col(\"TP\") + col(\"FN\")))\n",
    "    .withColumn(\"f1\", 2 * col(\"precision\") * col(\"recall\") /\n",
    "                        (col(\"precision\") + col(\"recall\")))\n",
    ")\n",
    "\n",
    "stats.select(\"fraud_flag\", \"precision\", \"recall\", \"f1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c32c96-704e-4120-a576-7847deeea920",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "150ad9c7-af82-4388-b106-06d47100de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "nb = NaiveBayes(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"fraud_flag\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8d997c8a-ea97-4240-a87b-7389290094c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages=indexers + [assembler, nb]\n",
    ")\n",
    "\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "644c9c27-66d2-4277-a59b-d11349a3ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"fraud_flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fc85ec95-c201-4ecb-a9f0-d520bab5f174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9999975420478796\n"
     ]
    }
   ],
   "source": [
    "auc = evaluator.evaluate(predictions)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a37525b-00bc-4eb7-b8db-0bc2451798b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+\n",
      "|fraud_flag|prediction|count|\n",
      "+----------+----------+-----+\n",
      "|         0|       0.0| 8991|\n",
      "|         1|       1.0|  181|\n",
      "+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = (\n",
    "    predictions\n",
    "    .groupBy(\"fraud_flag\", \"prediction\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c2b44fa-e7b2-468d-bcca-fd48b4845355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, when, coalesce, lit\n",
    "\n",
    "stats = (\n",
    "    cm\n",
    "    .groupBy(\"fraud_flag\")\n",
    "    .agg(\n",
    "        coalesce(\n",
    "            _sum(when(col(\"fraud_flag\") == col(\"prediction\"), col(\"count\"))),\n",
    "            lit(0)\n",
    "        ).alias(\"TP\"),\n",
    "        coalesce(\n",
    "            _sum(when(col(\"fraud_flag\") != col(\"prediction\"), col(\"count\"))),\n",
    "            lit(0)\n",
    "        ).alias(\"FN\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef204ee4-1b91-43c8-8620-8a481c652af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = (\n",
    "    cm\n",
    "    .groupBy(\"prediction\")\n",
    "    .agg(_sum(\"count\").alias(\"predicted_total\"))\n",
    "    .withColumnRenamed(\"prediction\", \"fraud_flag\")\n",
    ")\n",
    "\n",
    "stats = stats.join(fp, \"fraud_flag\")\n",
    "stats = stats.withColumn(\"FP\", col(\"predicted_total\") - col(\"TP\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6d5e7e5-f0a2-495a-9e44-9d54b56d44b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+---+\n",
      "|fraud_flag|precision|recall| f1|\n",
      "+----------+---------+------+---+\n",
      "|         1|      1.0|   1.0|1.0|\n",
      "|         0|      1.0|   1.0|1.0|\n",
      "+----------+---------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats = (\n",
    "    stats\n",
    "    .withColumn(\"precision\", col(\"TP\") / (col(\"TP\") + col(\"FP\")))\n",
    "    .withColumn(\"recall\", col(\"TP\") / (col(\"TP\") + col(\"FN\")))\n",
    "    .withColumn(\"f1\", 2 * col(\"precision\") * col(\"recall\") /\n",
    "                        (col(\"precision\") + col(\"recall\")))\n",
    ")\n",
    "\n",
    "stats.select(\"fraud_flag\", \"precision\", \"recall\", \"f1\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
